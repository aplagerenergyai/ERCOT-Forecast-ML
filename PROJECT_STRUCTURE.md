# ERCOT ML Pipeline - Complete Project Structure

## ğŸ“ File Organization

```
forecasting-ml/
â”‚
â”œâ”€â”€ ğŸ“Š STEP 1: FEATURE ENGINEERING
â”‚   â”œâ”€â”€ build_features.py                 âœ… Main feature engineering script
â”‚   â””â”€â”€ aml_build_features.yml            âœ… Azure ML job definition
â”‚
â”œâ”€â”€ ğŸ¤– STEP 2: MODEL TRAINING
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“‚ Core Training Scripts
â”‚   â”‚   â”œâ”€â”€ dataloader.py                 âœ… Data loading & preprocessing
â”‚   â”‚   â”œâ”€â”€ metrics.py                    âœ… Evaluation metrics (RMSE, MAE, MAPE, RÂ²)
â”‚   â”‚   â”œâ”€â”€ train_lgbm.py                 âœ… LightGBM training
â”‚   â”‚   â”œâ”€â”€ train_xgb.py                  âœ… XGBoost training
â”‚   â”‚   â””â”€â”€ train_deep.py                 âœ… Deep Learning (LSTM) training
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“‚ Azure ML Jobs (Individual)
â”‚   â”‚   â”œâ”€â”€ aml_train_lgbm.yml            âœ… LightGBM job (cpu-cluster)
â”‚   â”‚   â”œâ”€â”€ aml_train_xgb.yml             âœ… XGBoost job (cpu-cluster)
â”‚   â”‚   â””â”€â”€ aml_train_deep.yml            âœ… Deep Learning job (gpu-cluster)
â”‚   â”‚
â”‚   â””â”€â”€ ğŸ“‚ Azure ML Pipeline
â”‚       â””â”€â”€ aml_training_pipeline.yml     âœ… Parallel training pipeline
â”‚
â”œâ”€â”€ ğŸ”§ CONFIGURATION
â”‚   â”œâ”€â”€ requirements.txt                  âœ… Python dependencies
â”‚   â”œâ”€â”€ environment.yml                   âœ… Conda environment (updated)
â”‚   â””â”€â”€ .env                              âš ï¸  Create this (SQL credentials)
â”‚
â”œâ”€â”€ ğŸ“š DOCUMENTATION
â”‚   â”œâ”€â”€ README.md                         ğŸ“– Original project README
â”‚   â”œâ”€â”€ PIPELINE_GUIDE.md                 âœ… Complete usage guide
â”‚   â”œâ”€â”€ STEP2_SUMMARY.md                  âœ… Implementation summary
â”‚   â””â”€â”€ PROJECT_STRUCTURE.md              âœ… This file
â”‚
â””â”€â”€ ğŸ“‚ OUTPUT DIRECTORIES (created automatically)
    â”œâ”€â”€ data/features/                    â†’ hourly_features.parquet
    â””â”€â”€ outputs/                          â†’ trained models

```

---

## ğŸ”„ Data Flow Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         SQL SERVER                              â”‚
â”‚                      (9 ERCOT Tables)                           â”‚
â”‚                                                                 â”‚
â”‚  â€¢ hist_ActualSystemLoadbyForecastZone                         â”‚
â”‚  â€¢ hist_ActualSystemLoadbyWeatherZone                          â”‚
â”‚  â€¢ hist_DAMSettlementPointPrices                               â”‚
â”‚  â€¢ hist_LMPbyResourceNodesLoadZonesandTradingHubs              â”‚
â”‚  â€¢ hist_RealTimeLMP                                            â”‚
â”‚  â€¢ hist_SCEDShadowPricesandBindingTransmissionConstraints      â”‚
â”‚  â€¢ hist_SolarPowerProductionActual5MinuteAveragedValues        â”‚
â”‚  â€¢ hist_SolarPowerProductionHourlyAveragedActual...            â”‚
â”‚  â€¢ hist_WindPowerProductionHourlyAveragedActual...             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â”‚ pyodbc connection
                         â†“
         â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
         â•‘    build_features.py                  â•‘
         â•‘                                       â•‘
         â•‘  1. Load tables (chunked)             â•‘
         â•‘  2. Normalize timestamps              â•‘
         â•‘  3. Resample 5-min â†’ hourly           â•‘
         â•‘  4. Melt wide â†’ long                  â•‘
         â•‘  5. Merge all features                â•‘
         â•‘  6. Save to parquet                   â•‘
         â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¦â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                         â”‚
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              AZURE ML WORKSPACEBLOBSTORE                        â”‚
â”‚         features/hourly_features.parquet                        â”‚
â”‚                                                                 â”‚
â”‚  Columns:                                                       â”‚
â”‚    â€¢ TimestampHour (datetime)                                  â”‚
â”‚    â€¢ SettlementPoint (categorical, ~1053 values)               â”‚
â”‚    â€¢ DAM_Price_Hourly ($/MWh)                                  â”‚
â”‚    â€¢ RTM_LMP_HourlyAvg ($/MWh)                                 â”‚
â”‚    â€¢ Load_NORTH_Hourly, Load_SOUTH_Hourly, ...                 â”‚
â”‚    â€¢ Solar_Actual_Hourly, Solar_Forecast_STPPF_Hourly, ...     â”‚
â”‚    â€¢ Wind_Actual_System_Hourly, Wind_Forecast_STWPF_*, ...     â”‚
â”‚    â€¢ 50+ total features                                        â”‚
â”‚                                                                 â”‚
â”‚  Rows: ~1M+ (hours Ã— settlement points)                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â”‚ Read parquet
                         â†“
         â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
         â•‘    dataloader.py                      â•‘
         â•‘                                       â•‘
         â•‘  1. Load parquet                      â•‘
         â•‘  2. Create DART target                â•‘
         â•‘     DART = DAM - RTM                  â•‘
         â•‘  3. Time-based split                  â•‘
         â•‘     Train: 80% | Val: 10% | Test: 10%â•‘
         â•‘  4. Encode SettlementPoint            â•‘
         â•‘  5. Standardize features              â•‘
         â•šâ•â•â•â•â•â•â•â•¦â•â•â•â•â•â•â•â•â•â•â•â•¦â•â•â•â•â•â•â•â•â•â•â•â•¦â•â•â•â•â•â•â•â•
                 â”‚           â”‚           â”‚
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”   â”Œâ”€â”€â”€â”´â”€â”€â”€â”€â”€â”   â”Œâ”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚             â”‚   â”‚         â”‚   â”‚             â”‚
       â†“             â†“   â†“         â†“   â†“             â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LightGBM     â”‚ â”‚ XGBoost      â”‚ â”‚ Deep Learning    â”‚
â”‚              â”‚ â”‚              â”‚ â”‚ (LSTM)           â”‚
â”‚ â€¢ Gradient   â”‚ â”‚ â€¢ Extreme    â”‚ â”‚ â€¢ 2-layer LSTM   â”‚
â”‚   boosting   â”‚ â”‚   gradient   â”‚ â”‚ â€¢ 128 hidden dim â”‚
â”‚ â€¢ 1000 trees â”‚ â”‚   boosting   â”‚ â”‚ â€¢ Dropout 0.2    â”‚
â”‚ â€¢ Early stop â”‚ â”‚ â€¢ Early stop â”‚ â”‚ â€¢ Early stop     â”‚
â”‚              â”‚ â”‚              â”‚ â”‚                  â”‚
â”‚ cpu-cluster  â”‚ â”‚ cpu-cluster  â”‚ â”‚ gpu-cluster      â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                â”‚                  â”‚
       â†“                â†“                  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              AZURE ML WORKSPACEBLOBSTORE                        â”‚
â”‚                    models/                                      â”‚
â”‚                                                                 â”‚
â”‚  â€¢ lgbm/lgbm_model.pkl     (50-200 MB)                         â”‚
â”‚  â€¢ xgb/xgb_model.pkl       (50-200 MB)                         â”‚
â”‚  â€¢ deep/deep_model.pt      (10-50 MB)                          â”‚
â”‚                                                                 â”‚
â”‚  Each model includes:                                          â”‚
â”‚    - Trained model weights                                     â”‚
â”‚    - Feature column names                                      â”‚
â”‚    - StandardScaler (fitted on train)                          â”‚
â”‚    - Categorical encoders                                      â”‚
â”‚    - Train/Val/Test metrics                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¯ Target Variable

```python
DART_Spread = DAM_Price_Hourly - RTM_LMP_HourlyAvg

# Where:
#   DAM_Price_Hourly     = Day-Ahead Market clearing price
#   RTM_LMP_HourlyAvg    = Real-Time Market LMP (avg of 5-min values)
```

**Why DART matters**:
- Measures market forecasting accuracy
- Indicates supply/demand imbalances
- Key metric for energy traders and operators
- Typical range: -$50 to +$50 per MWh
- Goal: Predict with RMSE < $5/MWh

---

## ğŸ“Š Feature Categories

### Load Features (13)
From forecast zones + weather zones:
- `Load_NORTH_Hourly`, `Load_SOUTH_Hourly`, `Load_WEST_Hourly`
- `Load_HOUSTON_Hourly`, `Load_TOTAL_Hourly`
- `Load_COAST_Hourly`, `Load_EAST_Hourly`, etc.

### Solar Features (9)
System-wide generation and forecasts:
- **Actual**: `Solar_Actual_Hourly`
- **Capacity**: `Solar_HSL_Hourly` (High Sustained Limit)
- **Forecasts**: `Solar_Forecast_STPPF_Hourly`, `Solar_Forecast_PVGRPP_Hourly`
- **COP**: `Solar_COP_HSL_Hourly` (Current Operating Plan)

### Wind Features (17)
System + 3 regional breakdowns:
- **System**: `Wind_Actual_System_Hourly`, `Wind_HSL_System_Hourly`
- **South Houston**: `Wind_Actual_SOUTH_HOUSTON_Hourly`, forecasts, HSL
- **West**: `Wind_Actual_WEST_Hourly`, forecasts, HSL
- **North**: `Wind_Actual_NORTH_Hourly`, forecasts, HSL

### Price Features (2)
- `DAM_Price_Hourly` â†’ used to create target
- `RTM_LMP_HourlyAvg` â†’ used to create target

### Categorical (1)
- `SettlementPoint` â†’ Target-encoded (~1053 unique values)

---

## ğŸš€ Execution Commands

### Quick Start (Full Pipeline)

```bash
# 1. Build features (30-60 min)
az ml job create --file aml_build_features.yml --web

# 2. Train all models in parallel (30-60 min)
az ml job create --file aml_training_pipeline.yml --web
```

### Individual Model Training

```bash
# Train LightGBM only (10-20 min)
az ml job create --file aml_train_lgbm.yml --web

# Train XGBoost only (10-20 min)
az ml job create --file aml_train_xgb.yml --web

# Train Deep Learning only (30-60 min with GPU)
az ml job create --file aml_train_deep.yml --web
```

### Local Testing (requires .env file)

```bash
# Test feature engineering locally
python build_features.py

# Test model training locally (after features are built)
python train_lgbm.py
python train_xgb.py
python train_deep.py
```

---

## ğŸ” Required Credentials

Create `.env` file in project root:

```env
SQL_SERVER=your-server.database.windows.net
SQL_DATABASE=ERCOT
SQL_USERNAME=your-username
SQL_PASSWORD=your-password
```

---

## âš™ï¸ Compute Requirements

| Job Type          | Compute       | Cores | RAM    | GPU  | Time      |
|-------------------|---------------|-------|--------|------|-----------|
| Feature Build     | cpu-cluster   | 4-8   | 16-32G | No   | 30-60 min |
| LightGBM Train    | cpu-cluster   | 4-8   | 8-16G  | No   | 10-20 min |
| XGBoost Train     | cpu-cluster   | 4-8   | 8-16G  | No   | 10-20 min |
| Deep Learning     | gpu-cluster   | 4-8   | 16-32G | Yes  | 30-60 min |

---

## ğŸ“ˆ Expected Performance

Based on typical ERCOT DART spread prediction:

| Model         | RMSE ($/MWh) | MAE ($/MWh) | MAPE (%) | RÂ²    |
|---------------|--------------|-------------|----------|-------|
| LightGBM      | 3.0 - 5.0    | 2.0 - 3.5   | 15 - 25  | 0.75+ |
| XGBoost       | 3.0 - 5.0    | 2.0 - 3.5   | 15 - 25  | 0.75+ |
| Deep Learning | 4.0 - 6.0    | 3.0 - 4.5   | 20 - 30  | 0.70+ |

*Actual results depend on data quality, time period, and hyperparameters*

---

## âœ… Completion Checklist

### Step 1: Feature Engineering
- [x] SQL connection handling
- [x] Chunked loading for large tables
- [x] Timestamp normalization (3 formats)
- [x] 5-minute â†’ hourly resampling
- [x] Wide â†’ long melting
- [x] Settlement point merge (FIXED)
- [x] Parquet output to Azure ML

### Step 2: Model Training
- [x] Data loader with time-based split
- [x] DART target creation
- [x] Categorical encoding (TargetEncoder)
- [x] Feature standardization
- [x] LightGBM training script
- [x] XGBoost training script
- [x] Deep Learning (LSTM) script
- [x] Evaluation metrics (RMSE, MAE, MAPE, RÂ²)
- [x] Feature importance logging
- [x] Model serialization with metadata

### Azure ML Integration
- [x] Environment variable handling
- [x] Input/output path configuration
- [x] Individual job YAMLs (3)
- [x] Parallel pipeline YAML (1)
- [x] Compute cluster specification

### Documentation
- [x] Complete usage guide (PIPELINE_GUIDE.md)
- [x] Implementation summary (STEP2_SUMMARY.md)
- [x] Project structure (PROJECT_STRUCTURE.md)
- [x] Requirements file
- [x] Environment file

---

## ğŸ“ Learning Resources

### ERCOT Market Basics
- **DAM**: Day-Ahead Market (hourly auctions for next operating day)
- **RTM**: Real-Time Market (5-minute SCED dispatch)
- **DART**: Day-Ahead Real-Time spread (forecast error indicator)
- **LMP**: Locational Marginal Price (nodal pricing)
- **Settlement Points**: Nodes, hubs, load zones (~1053 total)

### Model Selection Guide
- **LightGBM**: Fast, memory-efficient, handles missing values
- **XGBoost**: Accurate, regularization built-in, slower than LightGBM
- **Deep Learning**: Captures complex patterns, requires more data/compute

---

## ğŸ“ Troubleshooting

See `PIPELINE_GUIDE.md` section "Troubleshooting" for:
- SQL connection issues
- Azure ML path problems
- Missing dependencies
- GPU configuration
- Data quality issues

---

## ğŸ¯ Next Steps

1. âœ… **Run Feature Engineering**: `az ml job create --file aml_build_features.yml`
2. â³ **Wait for Completion**: Check Azure ML Studio for job status
3. âœ… **Verify Parquet**: Ensure `hourly_features.parquet` exists in workspaceblobstore
4. âœ… **Run Training Pipeline**: `az ml job create --file aml_training_pipeline.yml`
5. ğŸ“Š **Compare Models**: Review metrics in Azure ML Studio
6. ğŸš€ **Deploy Best Model**: Register and create endpoint
7. ğŸ“ˆ **Monitor**: Set up drift detection and retraining schedule

---

**ğŸ‰ Pipeline Implementation Complete!**

All files are ready for execution. Follow the commands above to start training your ERCOT DART spread prediction models.

